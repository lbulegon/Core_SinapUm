#!/usr/bin/env python3
"""
Script para testar a an√°lise do conte√∫do de imagens e gera√ß√£o de JSON baseado no conte√∫do.
Este script:
1. Carrega imagens de teste
2. Analisa o conte√∫do atrav√©s de VLM (Vision Language Model)
3. Gera descri√ß√£o textual do conte√∫do
4. Processa a descri√ß√£o atrav√©s do LLM para gerar a√ß√µes em JSON
5. Valida se o JSON reflete corretamente o conte√∫do da imagem
"""

import asyncio
import base64
import json
import logging
import os
import sys
from pathlib import Path
from typing import Any, Dict, List, Optional

import json5
from PIL import Image

from tests.integration.mock_inputs.data_providers.mock_image_provider import (
    get_image_provider,
    load_test_images,
)
from tests.integration.test_case_runner import (
    load_test_case,
    load_test_images_from_config,
    run_test_case,
)

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)

# Adicionar caminho do OpenMind ao sys.path
OM1_DIR = Path("/root/openmind_ws/OM1")
if OM1_DIR.exists():
    sys.path.insert(0, str(OM1_DIR))

# Diret√≥rios - apontar para o OpenMind
BASE_DIR = OM1_DIR if OM1_DIR.exists() else Path(__file__).parent
TEST_CASES_DIR = BASE_DIR / "tests/integration/data/test_cases"
IMAGES_DIR = BASE_DIR / "tests/integration/data/images"


class ImageContentAnalyzer:
    """Classe para analisar conte√∫do de imagens e validar gera√ß√£o de JSON."""
    
    def __init__(self):
        self.image_descriptions = []
        self.json_outputs = []
        self.validation_results = []
    
    def analyze_image_content_basic(self, image_path: Path) -> Dict[str, Any]:
        """
        An√°lise b√°sica do conte√∫do da imagem (metadados, formato, etc.).
        
        Parameters
        ----------
        image_path : Path
            Caminho para a imagem
            
        Returns
        -------
        Dict[str, Any]
            Informa√ß√µes b√°sicas sobre a imagem
        """
        logger.info(f"üì∏ Analisando conte√∫do b√°sico da imagem: {image_path.name}")
        
        analysis = {
            "image_path": str(image_path),
            "image_name": image_path.name,
            "exists": False,
            "readable": False,
            "dimensions": None,
            "file_size_kb": None,
            "format": None,
            "mode": None,
            "content_analysis": {
                "has_content": False,
                "can_be_processed": False
            }
        }
        
        try:
            if not image_path.exists():
                analysis["error"] = f"Arquivo n√£o encontrado: {image_path}"
                logger.error(f"‚ùå {analysis['error']}")
                return analysis
            
            analysis["exists"] = True
            
            # Obter informa√ß√µes do arquivo
            file_size = image_path.stat().st_size
            analysis["file_size_kb"] = round(file_size / 1024, 2)
            
            # Tentar abrir e analisar a imagem
            with Image.open(image_path) as img:
                width, height = img.size
                analysis["dimensions"] = {"width": width, "height": height}
                analysis["format"] = img.format
                analysis["mode"] = img.mode
                analysis["readable"] = True
                
                # An√°lise b√°sica de conte√∫do
                analysis["content_analysis"]["has_content"] = width > 0 and height > 0
                analysis["content_analysis"]["can_be_processed"] = (
                    analysis["content_analysis"]["has_content"] and
                    img.format in ["JPEG", "PNG"] and
                    img.mode in ["RGB", "RGBA", "L"]
                )
                
                logger.info(f"‚úÖ Imagem analisada: {width}x{height}, formato: {img.format}")
                logger.info(f"   - Pode ser processada: {analysis['content_analysis']['can_be_processed']}")
        
        except Exception as e:
            analysis["error"] = f"Erro ao analisar imagem: {str(e)}"
            logger.error(f"‚ùå {analysis['error']}")
        
        return analysis
    
    async def analyze_image_content_with_vlm(
        self, 
        test_case_name: str
    ) -> Dict[str, Any]:
        """
        Analisa o conte√∫do da imagem usando VLM e gera JSON atrav√©s de caso de teste.
        
        Parameters
        ----------
        test_case_name : str
            Nome do caso de teste a executar
            
        Returns
        -------
        Dict[str, Any]
            Resultado completo da an√°lise incluindo descri√ß√£o VLM e JSON gerado
        """
        logger.info("\n" + "=" * 80)
        logger.info(f"AN√ÅLISE DE CONTE√öDO COM VLM - {test_case_name}")
        logger.info("=" * 80)
        
        result = {
            "test_case": test_case_name,
            "status": "pending",
            "image_analysis": None,
            "vlm_description": None,
            "json_actions": None,
            "content_validation": None,
            "errors": []
        }
        
        try:
            # Encontrar e carregar caso de teste
            test_case_path = None
            for path in TEST_CASES_DIR.glob("*.json5"):
                config = load_test_case(path)
                if config.get("name") == test_case_name:
                    test_case_path = path
                    break
            
            if not test_case_path:
                error_msg = f"Caso de teste n√£o encontrado: {test_case_name}"
                logger.error(f"‚ùå {error_msg}")
                result["errors"].append(error_msg)
                result["status"] = "error"
                return result
            
            config = load_test_case(test_case_path)
            logger.info(f"üìÑ Caso de teste carregado: {config.get('name')}")
            
            # Analisar imagens do caso de teste
            if "images" not in config.get("input", {}):
                error_msg = "Caso de teste n√£o possui imagens configuradas"
                logger.error(f"‚ùå {error_msg}")
                result["errors"].append(error_msg)
                result["status"] = "error"
                return result
            
            image_paths = config["input"]["images"]
            image_analyses = []
            
            logger.info(f"\nüì∏ Analisando {len(image_paths)} imagem(ns) do caso de teste:")
            
            for img_path_str in image_paths:
                img_path = Path(img_path_str)
                if not img_path.is_absolute():
                    clean_path = img_path_str.replace("../images/", "")
                    img_path = IMAGES_DIR / clean_path
                
                analysis = self.analyze_image_content_basic(img_path)
                image_analyses.append(analysis)
                
                if analysis.get("readable"):
                    logger.info(f"   ‚úÖ {img_path.name}: {analysis['dimensions']}")
                else:
                    logger.warning(f"   ‚ö†Ô∏è  {img_path.name}: n√£o p√¥de ser lida")
            
            result["image_analysis"] = image_analyses
            
            # Carregar imagens para processamento
            images = load_test_images_from_config(config)
            if images:
                load_test_images(images)
                logger.info(f"‚úÖ {len(images)} imagem(ns) carregada(s) no provider")
            
            # Executar caso de teste para obter an√°lise VLM e JSON
            logger.info("\nüöÄ Executando caso de teste para an√°lise de conte√∫do...")
            test_results = await run_test_case(config)
            
            # Extrair descri√ß√£o VLM da resposta bruta
            raw_response = test_results.get("raw_response", "")
            if raw_response:
                result["vlm_description"] = self._extract_vlm_description(raw_response)
                logger.info(f"\nüìù Descri√ß√£o VLM obtida:")
                if result["vlm_description"]:
                    logger.info(f"   {result['vlm_description'][:200]}...")
                else:
                    logger.warning("   ‚ö†Ô∏è  Descri√ß√£o VLM n√£o encontrada na resposta")
            
            # Extrair a√ß√µes JSON geradas
            actions = test_results.get("actions", [])
            result["json_actions"] = self._extract_json_actions(actions)
            
            logger.info(f"\nüìã A√ß√µes JSON geradas: {len(actions)} a√ß√£o(√µes)")
            for i, action in enumerate(actions, 1):
                action_type = getattr(action, "type", "unknown")
                action_value = getattr(action, "value", None)
                logger.info(f"   {i}. {action_type}: {action_value}")
            
            # Validar se o JSON reflete o conte√∫do da imagem
            result["content_validation"] = self.validate_content_vs_json(
                image_analyses,
                result["vlm_description"],
                result["json_actions"]
            )
            
            result["status"] = "success"
            self.validation_results.append(result)
            
        except Exception as e:
            error_msg = f"Erro ao analisar conte√∫do com VLM: {str(e)}"
            logger.error(f"‚ùå {error_msg}")
            result["errors"].append(error_msg)
            result["status"] = "error"
            import traceback
            logger.error(traceback.format_exc())
        
        return result
    
    def _extract_vlm_description(self, raw_response: str) -> Optional[str]:
        """
        Extrai a descri√ß√£o VLM da resposta bruta.
        
        Parameters
        ----------
        raw_response : str
            Resposta bruta do sistema
            
        Returns
        -------
        Optional[str]
            Descri√ß√£o VLM extra√≠da ou None
        """
        if not raw_response:
            return None
        
        # Tentar encontrar descri√ß√£o VLM na resposta
        # Formato comum: "INPUT: Vision\n// START\n{descri√ß√£o}\n// END"
        if "// START" in raw_response and "// END" in raw_response:
            start_idx = raw_response.find("// START") + len("// START")
            end_idx = raw_response.find("// END")
            if start_idx < end_idx:
                description = raw_response[start_idx:end_idx].strip()
                if description:
                    return description
        
        # Se n√£o encontrou no formato padr√£o, retornar parte da resposta
        # que parece ser descri√ß√£o visual
        lines = raw_response.split("\n")
        for line in lines:
            if any(keyword in line.lower() for keyword in ["see", "detect", "image", "scene", "visual"]):
                return line.strip()
        
        return raw_response[:500] if len(raw_response) > 500 else raw_response
    
    def _extract_json_actions(self, actions: List) -> List[Dict[str, Any]]:
        """
        Extrai a√ß√µes em formato JSON estruturado.
        
        Parameters
        ----------
        actions : List
            Lista de a√ß√µes do sistema
            
        Returns
        -------
        List[Dict[str, Any]]
            Lista de a√ß√µes em formato JSON
        """
        json_actions = []
        
        for i, action in enumerate(actions):
            action_dict = {
                "index": i + 1,
                "type": getattr(action, "type", "unknown"),
                "value": getattr(action, "value", None)
            }
            json_actions.append(action_dict)
        
        return json_actions
    
    def validate_content_vs_json(
        self,
        image_analyses: List[Dict[str, Any]],
        vlm_description: Optional[str],
        json_actions: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        Valida se o JSON gerado reflete corretamente o conte√∫do da imagem.
        
        Parameters
        ----------
        image_analyses : List[Dict[str, Any]]
            An√°lises das imagens
        vlm_description : Optional[str]
            Descri√ß√£o gerada pelo VLM
        json_actions : List[Dict[str, Any]]
            A√ß√µes JSON geradas
            
        Returns
        -------
        Dict[str, Any]
            Resultado da valida√ß√£o
        """
        logger.info("\n" + "-" * 80)
        logger.info("VALIDA√á√ÉO: Conte√∫do da Imagem vs JSON Gerado")
        logger.info("-" * 80)
        
        validation = {
            "valid": True,
            "score": 0.0,
            "checks": [],
            "warnings": [],
            "errors": []
        }
        
        # Check 1: Imagens foram analisadas
        readable_images = [a for a in image_analyses if a.get("readable", False)]
        if readable_images:
            validation["checks"].append({
                "check": "imagens_analisadas",
                "status": "pass",
                "message": f"{len(readable_images)} imagem(ns) analisada(s) com sucesso"
            })
            logger.info(f"‚úÖ {len(readable_images)} imagem(ns) analisada(s)")
        else:
            validation["errors"].append("Nenhuma imagem p√¥de ser analisada")
            validation["valid"] = False
            logger.error("‚ùå Nenhuma imagem p√¥de ser analisada")
        
        # Check 2: Descri√ß√£o VLM foi gerada
        if vlm_description:
            validation["checks"].append({
                "check": "vlm_description",
                "status": "pass",
                "message": f"Descri√ß√£o VLM gerada ({len(vlm_description)} caracteres)"
            })
            validation["score"] += 0.3
            logger.info(f"‚úÖ Descri√ß√£o VLM gerada: {len(vlm_description)} caracteres")
        else:
            validation["warnings"].append("Descri√ß√£o VLM n√£o foi gerada")
            logger.warning("‚ö†Ô∏è  Descri√ß√£o VLM n√£o foi gerada")
        
        # Check 3: A√ß√µes JSON foram geradas
        if json_actions:
            validation["checks"].append({
                "check": "json_actions",
                "status": "pass",
                "message": f"{len(json_actions)} a√ß√£o(√µes) JSON gerada(s)"
            })
            validation["score"] += 0.3
            logger.info(f"‚úÖ {len(json_actions)} a√ß√£o(√µes) JSON gerada(s)")
            
            # Analisar tipos de a√ß√µes
            action_types = [a.get("type") for a in json_actions]
            logger.info(f"   Tipos de a√ß√µes: {', '.join(set(action_types))}")
        else:
            validation["errors"].append("Nenhuma a√ß√£o JSON foi gerada")
            validation["valid"] = False
            logger.error("‚ùå Nenhuma a√ß√£o JSON foi gerada")
        
        # Check 4: Rela√ß√£o entre descri√ß√£o VLM e a√ß√µes JSON
        if vlm_description and json_actions:
            # Verificar se h√° coer√™ncia b√°sica
            vlm_lower = vlm_description.lower()
            
            # Verificar se a descri√ß√£o menciona objetos comuns que podem gerar a√ß√µes
            keywords_found = []
            common_keywords = ["dog", "cat", "person", "human", "object", "see"]
            
            for keyword in common_keywords:
                if keyword in vlm_lower:
                    keywords_found.append(keyword)
            
            if keywords_found:
                validation["checks"].append({
                    "check": "content_coherence",
                    "status": "pass",
                    "message": f"Coer√™ncia detectada: keywords {keywords_found}"
                })
                validation["score"] += 0.2
                logger.info(f"‚úÖ Coer√™ncia de conte√∫do: keywords detectados - {keywords_found}")
            else:
                validation["warnings"].append(
                    "N√£o foi poss√≠vel verificar coer√™ncia entre descri√ß√£o VLM e a√ß√µes"
                )
                logger.warning("‚ö†Ô∏è  Coer√™ncia n√£o p√¥de ser verificada")
        
        # Check 5: Estrutura das a√ß√µes JSON
        valid_action_types = ["move", "emotion", "speak"]
        valid_actions = [a for a in json_actions if a.get("type") in valid_action_types]
        
        if len(valid_actions) > 0:
            validation["checks"].append({
                "check": "json_structure",
                "status": "pass",
                "message": f"{len(valid_actions)} a√ß√£o(√µes) com estrutura v√°lida"
            })
            validation["score"] += 0.2
            logger.info(f"‚úÖ Estrutura JSON v√°lida: {len(valid_actions)} a√ß√£o(√µes)")
        else:
            validation["warnings"].append("A√ß√µes JSON podem n√£o estar no formato esperado")
            logger.warning("‚ö†Ô∏è  Estrutura JSON pode estar incorreta")
        
        # Normalizar score (0.0 a 1.0)
        validation["score"] = min(validation["score"], 1.0)
        
        # Determinar se passou (score >= 0.5)
        if validation["score"] < 0.5:
            validation["valid"] = False
        
        logger.info(f"\nüìä Score de valida√ß√£o: {validation['score']:.2f}/1.0")
        logger.info(f"   Status: {'‚úÖ PASSOU' if validation['valid'] else '‚ùå FALHOU'}")
        
        return validation
    
    def generate_content_analysis_report(self) -> str:
        """Gera relat√≥rio completo da an√°lise de conte√∫do."""
        report_lines = [
            "\n" + "=" * 80,
            "RELAT√ìRIO DE AN√ÅLISE DE CONTE√öDO DE IMAGENS",
            "=" * 80,
            "",
            f"üìä Total de an√°lises: {len(self.validation_results)}",
            "",
        ]
        
        for i, result in enumerate(self.validation_results, 1):
            report_lines.append(f"\n{'=' * 80}")
            report_lines.append(f"AN√ÅLISE {i}: {result.get('test_case', 'unknown')}")
            report_lines.append("=" * 80)
            
            status = result.get("status", "unknown")
            status_icon = "‚úÖ" if status == "success" else "‚ùå"
            report_lines.append(f"\n{status_icon} Status: {status}")
            
            # Informa√ß√µes da imagem
            image_analyses = result.get("image_analysis", [])
            if image_analyses:
                report_lines.append(f"\nüì∏ Imagens Analisadas: {len(image_analyses)}")
                for img_analysis in image_analyses:
                    if img_analysis.get("readable"):
                        dims = img_analysis.get("dimensions", {})
                        report_lines.append(
                            f"   - {img_analysis.get('image_name')}: "
                            f"{dims.get('width')}x{dims.get('height')}"
                        )
            
            # Descri√ß√£o VLM
            vlm_desc = result.get("vlm_description")
            if vlm_desc:
                report_lines.append(f"\nüìù Descri√ß√£o VLM:")
                report_lines.append(f"   {vlm_desc[:200]}...")
            
            # A√ß√µes JSON
            json_actions = result.get("json_actions", [])
            if json_actions:
                report_lines.append(f"\nüìã A√ß√µes JSON ({len(json_actions)}):")
                for action in json_actions:
                    report_lines.append(
                        f"   - {action.get('type')}: {action.get('value')}"
                    )
            
            # Valida√ß√£o
            validation = result.get("content_validation", {})
            if validation:
                score = validation.get("score", 0.0)
                valid = validation.get("valid", False)
                report_lines.append(f"\n‚úÖ Valida√ß√£o:")
                report_lines.append(f"   - Score: {score:.2f}/1.0")
                report_lines.append(f"   - Status: {'PASSOU' if valid else 'FALHOU'}")
                
                checks = validation.get("checks", [])
                if checks:
                    report_lines.append(f"   - Checks realizados: {len(checks)}")
                    for check in checks:
                        status_icon = "‚úÖ" if check.get("status") == "pass" else "‚ö†Ô∏è"
                        report_lines.append(
                            f"     {status_icon} {check.get('check')}: {check.get('message')}"
                        )
        
        report_lines.append("\n" + "=" * 80)
        
        return "\n".join(report_lines)
    
    def save_results_to_json(self, output_file: str = "image_content_analysis.json"):
        """Salva resultados da an√°lise em arquivo JSON."""
        output_path = BASE_DIR / output_file
        
        output_data = {
            "analysis_summary": {
                "total_analyses": len(self.validation_results),
                "timestamp": str(Path(__file__).stat().st_mtime)
            },
            "results": self.validation_results
        }
        
        try:
            with open(output_path, "w", encoding="utf-8") as f:
                json.dump(output_data, f, indent=2, ensure_ascii=False)
            
            logger.info(f"\nüíæ Resultados salvos em: {output_path}")
            return True
        except Exception as e:
            logger.error(f"‚ùå Erro ao salvar resultados: {str(e)}")
            return False


async def main():
    """Fun√ß√£o principal."""
    print("=" * 80)
    print("TESTE DE AN√ÅLISE DE CONTE√öDO DE IMAGENS E GERA√á√ÉO DE JSON")
    print("=" * 80)
    print()
    
    analyzer = ImageContentAnalyzer()
    
    # Casos de teste para analisar
    test_cases = [
        "coco_indoor_detection",
        "open_ai_indoor_test",
    ]
    
    # Executar an√°lises
    for test_case in test_cases:
        logger.info(f"\n{'=' * 80}")
        logger.info(f"Processando caso de teste: {test_case}")
        logger.info("=" * 80)
        
        result = await analyzer.analyze_image_content_with_vlm(test_case)
        
        if result.get("status") == "success":
            logger.info(f"\n‚úÖ An√°lise completa para: {test_case}")
        else:
            logger.error(f"\n‚ùå Falha na an√°lise para: {test_case}")
    
    # Gerar e exibir relat√≥rio
    report = analyzer.generate_content_analysis_report()
    print(report)
    
    # Salvar resultados
    analyzer.save_results_to_json("image_content_analysis.json")
    
    # Salvar relat√≥rio
    report_path = BASE_DIR / "image_content_analysis_report.txt"
    with open(report_path, "w", encoding="utf-8") as f:
        f.write(report)
    
    logger.info(f"\nüìÑ Relat√≥rio salvo em: {report_path}")
    
    print("\n" + "=" * 80)
    print("AN√ÅLISES CONCLU√çDAS")
    print("=" * 80)


if __name__ == "__main__":
    asyncio.run(main())

